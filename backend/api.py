print("--- VERSÃO 39 DO CÓDIGO A SER EXECUTADA ---")

from fastapi import FastAPI, HTTPException
from google.cloud import texttospeech, storage
import google.auth
import uuid
from typing import List, Dict, Any, Optional, TypedDict
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field

CLOUD_STORAGE_BUCKET = "agente-pessoal-ia"

class GraphState(TypedDict):
    """
    Represents the states of the emails processing graph.
    Attributes:
        emails: the incoming email list.
        summary_text: the summary of text generated by LLM.
        audio_url: the URL of the generated audio file.
        error: A string to store any error message that occur during execution.
    """
    emails: List[Dict[str, Any]]
    summary_text: str
    audio_url: str
    error: Optional[str]

class EmailItem(BaseModel):
    from_sender: Optional[str] = Field(alias="from")
    subject: Optional[str]
    snippet: Optional[str]

class EmailRequest(BaseModel):
    emails: List[EmailItem]

llm: Optional[ChatGoogleGenerativeAI] = None
tts_client: Optional[texttospeech.TextToSpeechClient] = None
storage_client: Optional[storage.Client] = None

app = FastAPI()

def initialize_clients():
    """
    Initializes clients for Google APIs (LLM, Text-to-Speech, Cloud Storage).
    Implements a singleton pattern to ensure that initialization only occurs once.
    """
    global llm, tts_client, storage_client

    if llm is not None:
        return

    print("INFO: Initializing Google Cloud Clients for the first time.")
    try:
        print("INFO: Initializing LLM Gemini 1.5 Flash...")
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")

        print("INFO: Initializing Text-to-Speech and Cloud Storage clients...")
        credentials, project_id = google.auth.default()
        tts_client = texttospeech.TextToSpeechClient(credentials=credentials)
        storage_client = storage.Client(credentials=credentials)

        print("INFO: Clients initialized successfully.")
    except Exception as e:
        print(f"CRITICAL ERROR initializing clients: {e}")
        raise RuntimeError(f"Não foi possível inicializar os serviços de IA: {e}")

def generate_summary_node(state: GraphState) -> Dict[str, Any]:
    """
    Graph node that generates a summary from the list of emails in the state.
    """
    print("INFO: Generating summary from emails...")
    emails = state.get("emails", [])
    if not emails:
        print("INFO: Empty email list. Generating default response.")
        return {"summary_text": "Você não tem novos e-mails não lidos."}

    if not llm:
        print("ERROR: LLM not initialized.")
        return {"error": "LLM not initialized."}

    try:
        prompt = ChatPromptTemplate.from_messages([
            ("system", "Você é uma assistente pessoal chamada IA. A sua tarefa é criar um resumo verbal, conciso e natural"
                       " dos e-mails não lidos do seu utilizador. Comece sempre com uma saudação. Seja direta e priorize o"
                       " que parece mais importante."),
            ("user", "Aqui estão os meus e-mails não lidos:\n\n{email_list}")
        ])
        output_parser = StrOutputParser()
        chain = prompt | llm | output_parser

        formatted_emails = "\n---\n".join([f"De: {e['from']}\nAssunto: {e['subject']}\nPrévia: {e['snippet']}" for e in emails])

        summary = chain.invoke({"email_list": formatted_emails})
        print("INFO: Summary generated successfully by LLM.")
        return {"summary_text": summary}

    except Exception as e:
        print(f"DETAILED ERROR in generate_summary_from_emails: {e}")
        return {"error": f"Failed to generate abstract with LLM: {e}"}

def text_to_speech_node(state: GraphState) -> Dict[str, Any]:
    """
    Converts the text to audio and returns the public URL.
    """
    print("INFO: Converting text to audio...")
    text_to_speak = state.get("summary_text")

    if not text_to_speak:
        print("ERROR: No summary text found in state to convert to audio.")
        return {"error": "No summary text found in state to convert to audio."}

    try:
        if not tts_client or not storage_client:
            print("ERROR: TTS Client or Storage not initialized.")
            return {"error": "TTS Client or Storage not initialized."}

        synthesis_input = texttospeech.SynthesisInput(text=text_to_speak)
        voice = texttospeech.VoiceSelectionParams(
            language_code="pt-BR",
            name="pt-BR-Wavenet-C"
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )

        response = tts_client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )

        bucket = storage_client.bucket(CLOUD_STORAGE_BUCKET)
        blob_name = f"summary-{uuid.uuid4()}.mp3"
        blob = bucket.blob(blob_name)

        blob.upload_from_string(response.audio_content, content_type="audio/mpeg")

        print(f"INFO: Audio uploaded successfully to {blob.public_url}")
        return {"audio_url": blob.public_url}

    except Exception as e:
        print(f"An error occurred while generating or uploading the audio: {e}")
        return {"error": f"An error occurred while generating or uploading the audio: {e}"}

def should_continue(state: GraphState) -> str:
    """
    Decision function. If an error was recorded in the state, the graph ends.
    Otherwise, it continues to the next step.
    """
    print("INFO: Checking condiction 'should_continue'...")
    if state.get("error"):
        print("INFO: Error detected in status. Ending the stream.")
        return END
    print("INFO: No errors detected. Flow continues.")
    return "text_to_speech"

workflow = StateGraph(GraphState)
workflow.add_node("summarizer", generate_summary_node)
workflow.add_node("text_to_speech", text_to_speech_node)
workflow.set_entry_point("summarizer")
workflow.add_conditional_edges(
    "summarizer",
    should_continue,
    {
        "text_to_speech": "text_to_speech",
        END: END
    }
)
workflow.add_edge("text_to_speech", END)
app_graph = workflow.compile()

@app.on_event("startup")
async def startup_event():
    initialize_clients()

@app.get("/")
def read_root():
    """
    API main endpoint.
    """
    return {"status": "online", "message": "Welcome to IA Personal Agent Backend. Go to /docs to see the endpoints."}

@app.post("/generate-summary-audio")
def generate_summary_endpoint(request_body: EmailRequest):
    """Receive a emails list, generates a smart summary, converts to audio, and returns the URL audio file."""
    print("INFO: Endpoint '/generate-summary-audio' called.")
    try:
        initial_state = {
            "emails": [email.model_dump(by_alias=True) for email in request_body.emails],
            "summary_text": "",
            "audio_url": "",
            "error": None
        }

        final_state = app_graph.invoke(initial_state)

        if final_state.get("error"):
            print(f"ERROR: The graph flow completed with an error: {final_state['error']}")
            raise HTTPException(status_code=500, detail=final_state["error"])

        print("INFO: Graph flow completed successfully.")
        return {
            "audio_url": final_state["audio_url"],
            "summary_text_for_debug": final_state["summary_text"]
        }
    except HTTPException as e:
        raise e
    except Exception as e:
        print(f"FATAL ERROR in endpoint /generate-summary-audio: {type(e).__name__} - {e}")
        raise HTTPException(status_code=500, detail=f"Ocorreu um erro interno inesperado: {type(e).__name__}")